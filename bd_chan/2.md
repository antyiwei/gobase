
# Go Concurrency Patterns：管道和取消

[翻译来自https://blog.golang.org/pipelines](https://blog.golang.org/pipelines)

### 介绍
Go的并发原语可以轻松构建流数据流水线，从而有效利用I / O和多个CPU。本文介绍了此类管道的示例，强调了操作失败时出现的细微差别，并介绍了干净地处理故障的技术。

### 什么是管道？

Go中没有正式的管道定义; 它只是众多并发程序中的一种。非正式地，管道是由通道连接的一系列阶段，其中每个阶段是一组运行相同功能的goroutine。在每个阶段，goroutines

* 通过入站通道从上游接收值
* 对该数据执行一些功能，通常产生新值
* 通过出站通道向下游发送值
每个阶段都有任意数量的入站和出站通道，第一级和最后一级除外，它们分别只有出站或入站通道。第一阶段有时被称为来源或 生产者 ; 最后一个阶段，水槽或消费者。

我们将从一个简单的示例管道开始，解释这些想法和技术。稍后，我们将提出一个更现实的例子。

### 平方数字

考虑一个有三个阶段的管道。

第一个阶段gen是将整数列表转换为发出列表中整数的通道的函数。该gen函数启动一个goroutine，它在通道上发送整数，并在发送完所有值后关闭通道：

```go
func gen(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out <- n
        }
        close(out)
    }()
    return out
}
```

第二阶段sq从通道接收整数并返回发出每个接收整数的平方的通道。在入站通道关闭且此阶段已将所有值发送到下游后，它将关闭出站通道：

```go
func sq(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}
```

该main函数设置管道并运行最后阶段：它从第二阶段接收值并打印每一个，直到通道关闭：

```
func main() {
    // Set up the pipeline.
    c := gen(2, 3)
    out := sq(c)

    // Consume the output.
    fmt.Println(<-out) // 4
    fmt.Println(<-out) // 9
}
```

由于sq其入站和出站通道具有相同的类型，我们可以任意次数组成它。我们也可以main像其他阶段一样重写为范围循环：

```go
func main() {
    // Set up the pipeline and consume the output.
    for n := range sq(sq(gen(2, 3))) {
        fmt.Println(n) // 16 then 81
    }
}
```

### 扇出，扇入

多个功能可以从同一个通道读取，直到该通道关闭为止; 这被称为扇出。这提供了一种在一组工作者之间分配工作以并行化CPU使用和I / O的方法。

函数可以从多个输入读取并继续执行，直到通过将输入通道多路复用到关闭所有输入时关闭的单个通道来关闭所有输入。这称为扇入。

我们可以改变我们的管道来运行两个实例sq，每个实例从相同的输入通道读取。我们在结果中引入一个新函数merge，to fan：

```go
func main() {
    in := gen(2, 3)

    // Distribute the sq work across two goroutines that both read from in.
    c1 := sq(in)
    c2 := sq(in)

    // Consume the merged output from c1 and c2.
    for n := range merge(c1, c2) {
        fmt.Println(n) // 4 then 9, or 9 then 4
    }
}
```

该merge函数通过为每个入站通道启动goroutine将一个通道列表转换为单个通道，该通道将值复制到唯一的出站通道。一旦所有outputgoroutine都已启动，merge在该通道上的所有发送完成后再启动一个goroutine来关闭出站通道。

发送一个封闭的通道恐慌，因此确保在调用close之前完成所有发送是很重要的。该 sync.WaitGroup类型提供了一种安排此同步的简单方法：

```go
func merge(cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Start an output goroutine for each input channel in cs.  output
    // copies values from c to out until c is closed, then calls wg.Done.
    output := func(c <-chan int) {
        for n := range c {
            out <- n
        }
        wg.Done()
    }
    wg.Add(len(cs))
    for _, c := range cs {
        go output(c)
    }

    // Start a goroutine to close out once all the output goroutines are
    // done.  This must start after the wg.Add call.
    go func() {
        wg.Wait()
        close(out)
    }()
    return out
}
```

### 停下来

我们的管道功能有一种模式：

所有发送操作完成后，阶段关闭其出站通道。
阶段保持从入站通道接收值，直到这些通道关闭。
此模式允许将每个接收阶段写为range循环，并确保在所有值成功发送到下游后所有goroutine都退出。

但在实际管道中，阶段并不总是接收所有入站值。有时这是设计的：接收器可能只需要一个值的子集来取得进展。更常见的是，阶段会提前退出，因为入站值表示较早阶段的错误。在任何一种情况下，接收器都不必等待剩余的值到达，并且我们希望早期阶段停止产生后续阶段不需要的值。

在我们的示例管道中，如果某个阶段无法使用所有入站值，则尝试发送这些值的goroutine将无限期地阻塞：

```go
    // Consume the first value from output.
    out := merge(c1, c2)
    fmt.Println(<-out) // 4 or 9
    return
    // Since we didn't receive the second value from out,
    // one of the output goroutines is hung attempting to send it.
}

```

这是资源泄漏：goroutines消耗内存和运行时资源，goroutine堆栈中的堆引用使数据不被垃圾收集。Goroutines不是垃圾收集; 他们必须自己退出。

即使下游阶段未能收到所有入站值，我们也需要安排管道的上游阶段退出。一种方法是将出站通道更改为具有缓冲区。缓冲区可以包含固定数量的值; 如果缓冲区中有空间，则立即发送操作：

```go
c := make(chan int, 2) // buffer size 2
c <- 1  // succeeds immediately
c <- 2  // succeeds immediately
c <- 3  // blocks until another goroutine does <-c and receives 1
```

当在通道创建时知道要发送的值的数量时，缓冲区可以简化代码。例如，我们可以重写gen以将整数列表复制到缓冲通道中，并避免创建新的goroutine：

```go
func gen(nums ...int) <-chan int {
    out := make(chan int, len(nums))
    for _, n := range nums {
        out <- n
    }
    close(out)
    return out
}
```

回到我们管道中阻塞的goroutines，我们可能会考虑为返回的出站通道添加一个缓冲区merge：

```go
func merge(cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int, 1) // enough space for the unread inputs
    // ... the rest is unchanged ...
```

虽然这修复了此程序中阻塞的goroutine，但这是错误的代码。此处缓冲区大小为1的选择取决于知道merge 将接收的值的数量以及下游阶段将消耗的值的数量。这很脆弱：如果我们传递一个额外的值gen，或者如果下游阶段读取任何更少的值，我们将再次阻止goroutines。

相反，我们需要为下游阶段提供一种方式，向发件人表明他们将停止接受输入。

### 明确取消

当main决定退出而不接收所有值时 out，它必须告诉上游阶段的goroutines放弃他们试图发送的值。它通过在名为的通道上发送值来实现done。它发送两个值，因为可能有两个阻塞的发件人：

```go
func main() {
    in := gen(2, 3)

    // Distribute the sq work across two goroutines that both read from in.
    c1 := sq(in)
    c2 := sq(in)

    // Consume the first value from output.
    done := make(chan struct{}, 2)
    out := merge(done, c1, c2)
    fmt.Println(<-out) // 4 or 9

    // Tell the remaining senders we're leaving.
    done <- struct{}{}
    done <- struct{}{}
}
```

发送goroutines用一个select语句替换它们的发送操作，该语句在发送out时或从接收到的值时继续done。值类型done是空结构，因为值无关紧要：它是指示out应该放弃发送的接收事件。所述output够程继续循环在其入站通道，c，所以上游阶段不被堵塞。（我们将在稍后讨论如何让这个循环尽早返回。）

```go 
func merge(done <-chan struct{}, cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Start an output goroutine for each input channel in cs.  output
    // copies values from c to out until c is closed or it receives a value
    // from done, then output calls wg.Done.
    output := func(c <-chan int) {
        for n := range c {
            select {
            case out <- n:
            case <-done:
            }
        }
        wg.Done()
    }
    // ... the rest is unchanged ...
```

这种方法存在一个问题：每个下游接收器需要知道可能被阻塞的上游发送器的数量，并安排在早期返回时发信号通知这些发送器。跟踪这些计数是乏味且容易出错的。

我们需要一种方法来告诉未知和无限数量的goroutine停止向下游发送它们的值。在Go中，我们可以通过关闭通道来完成此`操作`，因为 `关闭通道上的接收操作总是可以立即进行，从而产生元素类型的零值`。

这意味着main只需关闭done频道即可解锁所有发件人。这种关闭实际上是发送者的广播信号。我们将每个管道函数扩展为接受 done作为参数并通过defer语句安排接近发生 ，以便所有返回路径main将通知管道阶段退出。

```go

func main() {
    // Set up a done channel that's shared by the whole pipeline,
    // and close that channel when this pipeline exits, as a signal
    // for all the goroutines we started to exit.
    done := make(chan struct{})
    defer close(done)

    in := gen(done, 2, 3)

    // Distribute the sq work across two goroutines that both read from in.
    c1 := sq(done, in)
    c2 := sq(done, in)

    // Consume the first value from output.
    out := merge(done, c1, c2)
    fmt.Println(<-out) // 4 or 9

    // done will be closed by the deferred call.
}
```

我们的每个管道阶段现在都可以在done关闭后自由返回。在output常规merge可以返回而不消耗其入站通道，因为它知道上游发送者，sq将停止尝试时发送 done关闭。 output确保wg.Done通过defer语句在所有返回路径上调用：

同样，sq一旦done关闭就可以返回。 通过声明sq确保其out通道在所有返回路径上关闭defer：

```go
func sq(done <-chan struct{}, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            select {
            case out <- n * n:
            case <-done:
                return
            }
        }
    }()
    return out
}
```


以下是管道施工的指南：

所有发送操作完成后，阶段关闭其出站通道。
阶段保持从入站通道接收值，直到这些通道关闭或发件人被解锁。
管道通过确保为所有发送的值提供足够的缓冲区或通过在接收方放弃信道时显式地发送信令来发送信号，从而解锁发送方。

消化一棵树
让我们考虑一个更现实的管道。

MD5是一种消息摘要算法，可用作文件校验和。命令行实用程序md5sum打印文件列表的摘要值。

```go
% md5sum *.go
d47c2bbc28298ca9befdfbc5d3aa4e65  bounded.go
ee869afd31f83cbb2d10ee81b2b831dc  parallel.go
b88175e65fdcbc01ac08aaf1fd9b5e96  serial.go
```

我们的示例程序就像是，md5sum但是将一个目录作为参数，并打印该目录下每个常规文件的摘要值，按路径名排序。

```go
% go run serial.go .
d47c2bbc28298ca9befdfbc5d3aa4e65  bounded.go
ee869afd31f83cbb2d10ee81b2b831dc  parallel.go
b88175e65fdcbc01ac08aaf1fd9b5e96  serial.go
```

我们程序的主要功能是调用辅助函数MD5All，该函数将路径名称中的映射返回到摘要值，然后对结果进行排序和打印：

```go
func main() {
    // Calculate the MD5 sum of all files under the specified directory,
    // then print the results sorted by path name.
    m, err := MD5All(os.Args[1])
    if err != nil {
        fmt.Println(err)
        return
    }
    var paths []string
    for path := range m {
        paths = append(paths, path)
    }
    sort.Strings(paths)
    for _, path := range paths {
        fmt.Printf("%x  %s\n", m[path], path)
    }
}
```

该MD5All功能是我们讨论的重点。在 serial.go中，实现不使用并发，只是在每个文件遍历树时读取和求和。

```go
// MD5All reads all the files in the file tree rooted at root and returns a map
// from file path to the MD5 sum of the file's contents.  If the directory walk
// fails or any read operation fails, MD5All returns an error.
func MD5All(root string) (map[string][md5.Size]byte, error) {
    m := make(map[string][md5.Size]byte)
    err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        if !info.Mode().IsRegular() {
            return nil
        }
        data, err := ioutil.ReadFile(path)
        if err != nil {
            return err
        }
        m[path] = md5.Sum(data)
        return nil
    })
    if err != nil {
        return nil, err
    }
    return m, nil
}
```

平行消化
在parallel.go，我们分裂MD5All成两个阶段的管道。第一个阶段，sumFiles遍历树，在新的goroutine中消化每个文件，并在值为类型的通道上发送结果result：

```go
    type result struct {
        path string
        sum  [md5.Size]byte
        err  error
    }
```

sumFiles返回两个通道：一个用于results和另一个用于返回的错误filepath.Walk。walk函数启动一个新的goroutine来处理每个常规文件，然后检查done。如果done关闭，步行立即停止：

```go
func sumFiles(done <-chan struct{}, root string) (<-chan result, <-chan error) {
    // For each regular file, start a goroutine that sums the file and sends
    // the result on c.  Send the result of the walk on errc.
    c := make(chan result)
    errc := make(chan error, 1)
    go func() {
        var wg sync.WaitGroup
        err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
            if err != nil {
                return err
            }
            if !info.Mode().IsRegular() {
                return nil
            }
            wg.Add(1)
            go func() {
                data, err := ioutil.ReadFile(path)
                select {
                case c <- result{path, md5.Sum(data), err}:
                case <-done:
                }
                wg.Done()
            }()
            // Abort the walk if done is closed.
            select {
            case <-done:
                return errors.New("walk canceled")
            default:
                return nil
            }
        })
        // Walk has returned, so all calls to wg.Add are done.  Start a
        // goroutine to close c once all the sends are done.
        go func() {
            wg.Wait()
            close(c)
        }()
        // No select needed here, since errc is buffered.
        errc <- err
    }()
    return c, errc
}
```

MD5All从中接收摘要值c。 MD5All错误时提前返回，done通过以下方式关闭defer：

```go
func MD5All(root string) (map[string][md5.Size]byte, error) {
    // MD5All closes the done channel when it returns; it may do so before
    // receiving all the values from c and errc.
    done := make(chan struct{})
    defer close(done)

    c, errc := sumFiles(done, root)

    m := make(map[string][md5.Size]byte)
    for r := range c {
        if r.err != nil {
            return nil, r.err
        }
        m[r.path] = r.sum
    }
    if err := <-errc; err != nil {
        return nil, err
    }
    return m, nil
}
```

有限的并行性
`parallel.go中` 的MD5All实现 为每个文件启动一个新的goroutine。在具有许多大文件的目录中，这可能会分配比计算机上可用内存更多的内存。

我们可以通过限制并行读取的文件数来限制这些分配。`在bounded.go中`，我们通过创建固定数量的goroutine来读取文件。我们的管道现在有三个阶段：走树，读取和消化文件，并收集摘要。

第一个阶段，walkFiles发出树中常规文件的路径：

```go
func walkFiles(done <-chan struct{}, root string) (<-chan string, <-chan error) {
    paths := make(chan string)
    errc := make(chan error, 1)
    go func() {
        // Close the paths channel after Walk returns.
        defer close(paths)
        // No select needed for this send, since errc is buffered.
        errc <- filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
            if err != nil {
                return err
            }
            if !info.Mode().IsRegular() {
                return nil
            }
            select {
            case paths <- path:
            case <-done:
                return errors.New("walk canceled")
            }
            return nil
        })
    }()
    return paths, errc
}
```

中间阶段启动固定数量的digestergoroutine，从通道接收文件名paths并results在通道上发送c：

```go
func digester(done <-chan struct{}, paths <-chan string, c chan<- result) {
    for path := range paths {
        data, err := ioutil.ReadFile(path)
        select {
        case c <- result{path, md5.Sum(data), err}:
        case <-done:
            return
        }
    }
}
```

与前面的示例不同，digester不会关闭其输出通道，因为多个goroutine正在共享通道上发送。相反，代码MD5All 安排digesters在完成所有操作后关闭频道：

```go 
   // Start a fixed number of goroutines to read and digest files.
    c := make(chan result)
    var wg sync.WaitGroup
    const numDigesters = 20
    wg.Add(numDigesters)
    for i := 0; i < numDigesters; i++ {
        go func() {
            digester(done, paths, c)
            wg.Done()
        }()
    }
    go func() {
        wg.Wait()
        close(c)
    }()
```

我们可以让每个消化器创建并返回自己的输出通道，但是我们需要额外的goroutine来扇入结果。

最后阶段接收所有results从那里c检查错误errc。此检查不会更早发生，因为在此之前，walkFiles可能阻止向下游发送值：

```go
    m := make(map[string][md5.Size]byte)
    for r := range c {
        if r.err != nil {
            return nil, r.err
        }
        m[r.path] = r.sum
    }
    // Check whether the Walk failed.
    if err := <-errc; err != nil {
        return nil, err
    }
    return m, nil
}
```

### 结论

本文介绍了在Go中构建流数据管道的技术。处理此类管道中的故障非常棘手，因为管道中的每个阶段都可能阻止尝试向下游发送值，并且下游阶段可能不再关心传入的数据。我们展示了关闭一个通道如何向管道启动的所有goroutine广播“完成”信号，并定义正确构建管道的准则。

进一步阅读：

`Go Concurrency Patterns（视频）`介绍了Go的并发原语的基础知识以及应用它们的几种方法。
`Advanced Go Concurrency Patterns（视频）`涵盖了Go的基元的更复杂的用法，尤其是select。
Douglas McIlroy的论文`Squinting at Power Series`展示了Go-like并发性如何为复杂的计算提供优雅的支持。